# AIリスクアセスメント言語システム

## 📋 概要

本プロジェクトは、LLM（大規模言語モデル）を言語シミュレータとして活用し、AIシステムのリスクを体系的に特定・分析・評価し、適切な対策を導出する**実装済みの動作するシステム**です。

Partnership AIの事故データベースを参考に、**13種類のガイドワード**（データ5種、モデル4種、運用4種）に基づいて、**過酷度・発生頻度・回避可能性**の3軸でリスクを因数分解し、これらを改善することで対策を導出するアプローチを採用しています。

## ✨ 実装状況

- ✅ **バックエンド実装完了**（Python + FastAPI）
- ✅ **フロントエンド実装完了**（React + TypeScript + Vite）
- ✅ **LLM統合**（OpenAI GPT-4 / Anthropic Claude）
- ✅ **データベース設計**（PostgreSQL + SQLAlchemy）
- ✅ **Docker環境**（docker-compose対応）
- ✅ **テストコード**（pytest）

## 📁 ドキュメント構成

### 1. システムアーキテクチャ図 (`system_architecture.md`)

システム全体の構造を視覚化した図表集です。

**含まれる図**:
- ✅ システム全体図
- ✅ リスク特定プロセスフロー
- ✅ リスク分析・評価フロー
- ✅ 対策導出メカニズム
- ✅ LLMプロンプトフロー
- ✅ データモデル（ER図）

**対象読者**: システムアーキテクト、技術リーダー

**用途**: 
- システム設計の理解
- 開発チームへの説明
- 技術選定の根拠

### 2. システム仕様書 (`system_specification.md`)

システムの詳細な機能仕様と技術仕様をまとめた包括的なドキュメントです。

**主要セクション**:
1. **システム概要**: 目的、特徴、対象ユーザー
2. **システム要件**: 機能要件、非機能要件
3. **機能仕様**: 
   - リスク特定機能（ガイドワード定義含む）
   - リスク分析・評価機能（3因子の評価基準）
   - 対策導出機能（3つのアプローチ）
4. **LLMプロンプト設計**: 各機能のプロンプトテンプレート
5. **API仕様**: REST APIエンドポイント定義
6. **データ仕様**: データベーススキーマ
7. **システムアーキテクチャ**: レイヤー構成、技術スタック
8. **セキュリティ要件**: 認証・認可、データ保護
9. **パフォーマンス要件**: レスポンスタイム、スケーラビリティ
10. **運用・保守**: デプロイ、モニタリング、バックアップ

**対象読者**: 開発者、プロジェクトマネージャー、システムアーキテクト

**用途**:
- 開発の指針
- 要件の確認
- システムの理解

### 3. テストケース仕様書 (`test_specification.md`)

品質保証のための包括的なテストケース集です。

**テストレベル**:
1. **単体テスト**: 個別関数・メソッドの検証
   - リスク特定サービス
   - リスク評価サービス
   - 対策導出サービス
2. **統合テスト**: コンポーネント間連携
   - エンドツーエンド処理
   - データベーストランザクション
   - LLM API統合
3. **LLMプロンプトテスト**: プロンプト品質評価
   - 一貫性テスト
   - プロンプトインジェクション対策
4. **E2Eテスト**: ユーザーシナリオの検証
5. **パフォーマンステスト**: 負荷テスト、ストレステスト
6. **セキュリティテスト**: OWASP Top 10対応
7. **ユーザビリティテスト**: SUS評価、アクセシビリティ

**対象読者**: QAエンジニア、開発者

**用途**:
- テスト計画の作成
- テストの実装
- 品質基準の確認

### 4. 利用ガイド (`user_guide.md`)

エンドユーザーと開発者向けの完全な利用マニュアルです。

**主要セクション**:

**ユーザー向け**:
1. **クイックスタート**: 5分でできるアセスメント
2. **ユーザーガイド**: 
   - リスク状況の記述方法
   - リスク特定結果の確認
   - リスク評価の理解
   - 対策の選択
   - レポート機能
3. **FAQ**: よくある質問と回答
4. **トラブルシューティング**: 問題解決ガイド

**開発者向け**:
1. **API利用ガイド**: 
   - 認証方法
   - エンドポイント使用例
   - Python SDK
   - エラーハンドリング
2. **開発者ガイド**:
   - ローカル環境セットアップ
   - アーキテクチャ解説
   - コーディング規約
   - デプロイメント

**対象読者**: システム利用者、API利用者、開発者

**用途**:
- システムの操作方法学習
- API統合の実装
- 開発環境の構築

### 5. 実装サンプルコード (`implementation_samples.md`)

主要コンポーネントの実装例を集めたコード集です。

**含まれるサンプル**:
1. **バックエンド実装**:
   - リスク特定サービス（Python）
   - リスク評価サービス（Python）
   - 対策導出サービス（Python）
2. **LLMプロンプト実装**:
   - プロンプト定義クラス
   - LLMクライアント（OpenAI/Claude対応）
3. **フロントエンド実装**:
   - Reactコンポーネント（TypeScript）
   - カスタムフック
4. **データベースモデル**:
   - SQLAlchemyモデル定義
5. **テストコード**:
   - 単体テストの例
   - 統合テストの例

**対象読者**: 開発者

**用途**:
- 実装の参考
- コーディング標準の理解
- ベストプラクティスの学習

## 🎯 システムの特徴

### 1. ガイドワードベースのリスク特定

13種類のガイドワードで網羅的にリスクを洗い出します:

**データカテゴリ**:
- 網羅性
- 分布シフト
- 差別と偏見
- 著作権
- センシティブ

**モデルカテゴリ**:
- 配慮の欠如
- 例外処理
- 無傾向データ
- 公平性

**運用カテゴリ**:
- 誤使用
- 人間の監視
- 社会的評価の低下
- 基本権侵害

### 2. 3軸によるリスク因数分解

各リスクを以下の3つの因子で定量評価します:

1. **過酷度（Severity）**: 被害の深刻さ（1-5点）
2. **発生頻度（Frequency）**: 発生する確率（1-5点）
3. **回避可能性（Avoidability）**: 検知・対応の難易度（1-5点）

### 3. 3つのアプローチによる対策導出

評価結果に基づき、以下のアプローチで対策を生成します:

1. **過酷度低減**: 被害の軽減、影響範囲の限定
2. **発生頻度低減**: 原因除去、予防措置
3. **回避可能性向上**: 検知能力向上、対応体制整備

## 🚀 クイックスタート

### Dockerで起動（推奨）

```bash
# 1. 環境変数の設定
cp backend/.env.example .env
# .envファイルを編集してLLM APIキーを設定
# OPENAI_API_KEY=sk-xxx または ANTHROPIC_API_KEY=sk-ant-xxx

# 2. Dockerコンテナの起動
docker-compose up -d

# 3. ブラウザでアクセス
# フロントエンド: http://localhost:3000
# バックエンドAPI: http://localhost:8000
# APIドキュメント: http://localhost:8000/docs
```

### ローカル開発環境

**バックエンド:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env  # APIキーを設定
uvicorn app.main:app --reload --port 8000
```

**フロントエンド:**
```bash
cd frontend
npm install
npm run dev  # http://localhost:3000 で起動
```

詳細は `SETUP.md` を参照してください。

### システム利用の流れ

1. **リスク状況入力**: AIシステムの状況を記述
2. **リスク特定**: 自動的にリスクが洗い出される（約30秒）
3. **リスク評価**: 各リスクを3軸で評価（約15秒/リスク）
4. **対策確認**: 推奨される対策を確認

**所要時間**: 約30-50分

## 📊 言語システムのフロー

```
┌─────────────┐
│ AIリスク状況 │
│   入力      │
└──────┬──────┘
       │
       ▼
┌──────────────────┐
│ LLM言語シミュレータ│
│ (リスク特定)      │
│ ← ガイドワード    │
└──────┬───────────┘
       │
       ▼
┌──────────────┐
│特定されたリスク│ (複数)
└──────┬───────┘
       │
       ▼
┌──────────────────┐
│ LLM言語シミュレータ│
│ (リスク評価)      │
│ → 過酷度         │
│ → 発生頻度        │
│ → 回避可能性      │
└──────┬───────────┘
       │
       ▼
┌──────────────┐
│リスクレベル判定│ (高・中・低)
└──────┬───────┘
       │
       ▼
┌──────────────────┐
│ LLM言語シミュレータ│
│ (対策導出)        │
│ → 過酷度低減策    │
│ → 発生頻度低減策  │
│ → 回避可能性向上策│
└──────┬───────────┘
       │
       ▼
┌──────────────┐
│ 推奨対策リスト │
│ + レポート    │
└───────────────┘
```

## 💡 使用例

### 例1: 自動運転システムの死亡事故

**入力**:
```
自動運転の実験中。夜間、白線がかすれた横断歩道で、
歩行者に接触する死亡事故が発生。
```

**特定されたリスク**:
- 網羅性: 夜間データ不足
- 配慮の欠如: 劣化した路面標示への対応不足
- 人間の監視: 夜間走行時の監視体制不足

**評価結果**（網羅性リスク）:
- 過酷度: 5点（死亡事故）
- 発生頻度: 4点（夜間走行は頻繁）
- 回避可能性: 4点（検知困難）
- リスクレベル: **高**

**推奨対策**:
1. 夜間・悪天候データでの再学習（発生頻度低減）
2. 自動緊急ブレーキの強化（過酷度低減）
3. 夜間走行時の速度制限と監視強化（回避可能性向上）

### 例2: 採用AIの差別的判定

**入力**:
```
採用AIが特定の性別や人種を不当に低評価し、
採用機会の不平等が発生。
```

**特定されたリスク**:
- 差別と偏見: 学習データのバイアス
- 公平性: 特定グループへの不利な判定
- 基本権侵害: 雇用機会の平等を侵害

**推奨対策**:
- データの多様性確保とバイアス除去
- 公平性指標による継続的モニタリング
- 人間レビュープロセスの導入

## 📦 プロジェクト構成

```
.
├── backend/                    # バックエンド（Python + FastAPI）
│   ├── app/
│   │   ├── api/routes/        # APIエンドポイント
│   │   ├── services/          # ビジネスロジック
│   │   ├── models/            # データベースモデル
│   │   ├── schemas/           # Pydanticスキーマ
│   │   ├── llm/              # LLM統合
│   │   └── tests/            # テストコード
│   └── requirements.txt
├── frontend/                   # フロントエンド（React + TypeScript）
│   ├── src/
│   │   ├── components/       # Reactコンポーネント
│   │   ├── hooks/            # カスタムフック
│   │   ├── services/         # APIクライアント
│   │   └── types/            # TypeScript型定義
│   └── package.json
├── spec/                       # 仕様書
├── docker-compose.yml          # Docker Compose設定
├── SETUP.md                    # セットアップガイド
└── README.md
```

## 📈 システム要件

### 機能要件
- ✅ ガイドワードベースのリスク特定
- ✅ 3軸によるリスク評価
- ✅ 対策の自動生成
- 🚧 レポート出力（今後実装予定）

### 非機能要件
- ⚡ レスポンスタイム: 30秒以内（リスク特定）
- 👥 同時接続: 100ユーザー
- 🔒 セキュリティ: CORS設定、入力検証
- 📊 可用性: 99.5%以上（目標）

### 技術スタック
- **バックエンド**: Python 3.11+, FastAPI, SQLAlchemy
- **フロントエンド**: React 18, TypeScript, Vite
- **LLM**: OpenAI GPT-4 / Anthropic Claude
- **データベース**: PostgreSQL 15
- **インフラ**: Docker, Docker Compose

## 📚 参考資料

1. Partnership on AI - AI Incident Database
2. ISO/IEC 23894:2023 - AI Risk Management
3. NIST AI Risk Management Framework
4. EU AI Act
5. 総務省「AI利活用ガイドライン」

## 🤝 サポート

### 技術サポート
- **メール**: support@example.com
- **ドキュメント**: 本プロジェクトのドキュメント一式を参照

### コントリビューション
- **Issue**: 問題や改善提案は Issue で報告
- **Pull Request**: コードやドキュメントの改善は PR で提案

## 📝 ライセンス

本ドキュメントは参考実装仕様です。実際のプロジェクトに応じてカスタマイズしてください。

## 🎓 学習リソース

### 初心者向け
1. `user_guide.md` のクイックスタートから始める
2. サンプルシナリオで実際にアセスメントを体験
3. FAQ で疑問を解消

### 開発者向け
1. `system_architecture.md` でシステム全体像を把握
2. `system_specification.md` で詳細仕様を確認
3. `implementation_samples.md` でコードを学習
4. `test_specification.md` でテスト戦略を理解

### プロジェクトマネージャー向け
1. システム概要と特徴を理解
2. 要件定義を確認
3. テスト計画を把握
4. 運用・保守要件を確認

## 🔄 アップデート履歴

| バージョン | 日付 | 変更内容 |
|-----------|------|----------|
| 1.1.0 | 2025-11-08 | フロントエンド実装完了（React + TypeScript） |
| 1.0.0 | 2025-11-08 | バックエンド実装完了、初版リリース |
| 0.1.0 | 2025-11-08 | 仕様書作成 |

## 🎯 今後の予定

- [ ] データベースマイグレーション（Alembic）
- [ ] 認証・認可機能
- [ ] レポート生成機能（PDF出力）
- [ ] 統合テスト・E2Eテストの充実
- [ ] CI/CD パイプライン
- [ ] パフォーマンス最適化

---

**作成日**: 2025年11月8日
**最終更新**: 2025年11月8日
**バージョン**: 1.1.0