やっぱり、インシデントが発生した状況に対して、ガイドワードで複数のリスクが特定されたら、それぞれリスクを評価して、そのうえで、複数リスクをユーザーに選ばせて、対策は複数出てくるだろうが、まずは直接的に、「頻度を下げる→対策」のようなLLMに丸投げでなくて、いったんメタな方法、例えば下に上げたように、性能を上げる、ガードする、前提条件を定義、契約をちゃんとする、といった、を挟んでから具体的な対策に展開してほしいところ。

- 頻度を下げる→例えば、AIの性能を上げる
- 回避可能性を上げる→例えば、AIの外側でガードするよな設計
- 過酷度を下げる→例えば、前提条件を定義して、こんなデータが以外は使えないというようにするとか。契約をちゃんとするとか

そうすると、システマティックなアプローチとしては、

- インシデント発生状況→ガイドワードでリスクを特定（複数）
- 特定された（複数の）リスクを評価、
- どれを対策するかを選ばせて（複数）
- それぞれのリスクに対して、因数分解、すなわち、頻度を下げる、回避可能性を上げる、過酷度を下げる、それぞれに対して、メタな対策をいったん挟んで、具体的な対策に展開
- メタな対策って、複数のリスクで重なる場合があるから、それらはシステム的に統合すれば、複数のリスクに対してシステマティックに対応するというようなシステム思考が可能になる。

さいごの今の様子を曼陀羅のようにチャートとして可視化出来たら天才。